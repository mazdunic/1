Coursera - Machine Learning Project
Maz Dunic
Sunday, January 25, 2015
Writeup submission.
## Load training data
TrainingdataRaw <- read.csv(file="pml-training.csv")
## Create copy to work with and investigate
Trainingdata <- TrainingdataRaw
##summary(Trainingdata)
## >>  Identified a number of columns that are redundant, so checking testing file.
 
## Load Testing file & investigate
data2Pred <- read.csv(file="pml-testing.csv")
##summary(data2Pred)
## >> A large number of columns are blank.

## Remove blank variables
data2Pred2 <- data2Pred[,colSums(is.na(data2Pred))<nrow(data2Pred)]
## Remove ID column
data2Pred2$ID <- NULL
## Add back the Target variable
data2Pred2$classe <- data2Pred$classe

## Remove the same variables from the Training data.
Trainingdata2 <- Trainingdata[names(Trainingdata) %in% names(data2Pred2)]

## Load caret
library(caret)
## Loading required package: lattice
## Loading required package: ggplot2
## Split the data, and create reproducible seed.
set.seed(150)
inTrain <- createDataPartition(y=Trainingdata2$classe, p=0.75, list=FALSE)
training <- Trainingdata2[inTrain,]
testing <- Trainingdata2[-inTrain,]

## create a randomForest model, default values.
modFit <- train(classe ~ ., method="rf",data=training, ntrees=10)
## Loading required package: randomForest
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
## Check model performance
## View variable importance
varImp(modFit)
## rf variable importance
## 
##   only 20 most important variables shown (out of 80)
## 
##                                Overall
## raw_timestamp_part_1           100.000
## roll_belt                       41.847
## num_window                      41.369
## pitch_forearm                   27.901
## magnet_dumbbell_z               17.660
## magnet_dumbbell_y               14.057
## yaw_belt                        12.492
## pitch_belt                      11.919
## cvtd_timestamp30/11/2011 17:12  10.699
## roll_forearm                    10.422
## cvtd_timestamp2/12/2011 13:33    8.949
## cvtd_timestamp2/12/2011 14:58    8.868
## cvtd_timestamp28/11/2011 14:15   7.506
## magnet_dumbbell_x                6.986
## accel_belt_z                     6.914
## roll_dumbbell                    5.712
## magnet_belt_y                    5.490
## accel_dumbbell_y                 5.103
## accel_forearm_x                  5.060
## cvtd_timestamp5/12/2011 11:24    4.791
modFit$finalModel
## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, ntrees = 10) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 41
## 
##         OOB estimate of  error rate: 0.06%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 4185    0    0    0    0 0.0000000000
## B    3 2844    1    0    0 0.0014044944
## C    0    3 2564    0    0 0.0011686794
## D    0    0    1 2410    1 0.0008291874
## E    0    0    0    0 2706 0.0000000000
predict(modFit,newdata=data2Pred2)
##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E

